{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:35:35.200930Z",
     "start_time": "2018-05-20T14:35:35.194214Z"
    }
   },
   "source": [
    "### Variable Aggregation and Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:35:35.347606Z",
     "start_time": "2018-05-20T14:35:35.285826Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",30)\n",
    "pd.set_option(\"display.max_rows\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:35:35.417515Z",
     "start_time": "2018-05-20T14:35:35.349933Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:35:35.480348Z",
     "start_time": "2018-05-20T14:35:35.420135Z"
    }
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd().replace('/notebooks','')\n",
    "data_dir = os.path.join(cwd, 'data')\n",
    "season = '2014-15'\n",
    "weighting = 'quad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:35:35.736660Z",
     "start_time": "2018-05-20T14:35:35.482932Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, 'Dataframes', 'clean', 'df_{}.csv'.format(season)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe for the Baseline Model\n",
    "Mean of past N-1 games for each statistic when predicting N-th game performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:35:36.326483Z",
     "start_time": "2018-05-20T14:35:36.213129Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline = {'Date':[], 'Name':[], 'FPTS':[], 'PTS':[], '3P':[], 'AST':[],\n",
    "            'TRB':[], 'STL':[], 'BLK':[], 'TOV':[], 'DD':[], 'TD':[]}\n",
    "\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    \n",
    "    date = df.loc[i,'Date']\n",
    "    name = df.loc[i,'Name']    \n",
    "    \n",
    "    df_name = df.loc[df['Name']==name].reset_index(drop=True)\n",
    "    index = df_name.loc[df_name['Date']==date].index[0]\n",
    "    \n",
    "    #Check if there is past statistics available\n",
    "    if index >= 1:\n",
    "        \n",
    "        df_past = df_name[0:index].reset_index(drop=True)\n",
    "        \n",
    "        for key in baseline.keys():\n",
    "            if key in ['Date', 'Name', 'FPTS']:\n",
    "                baseline[key].append(df_name.loc[index, key])\n",
    "                \n",
    "            else:\n",
    "                baseline[key].append(df_past[key].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:35:36.389524Z",
     "start_time": "2018-05-20T14:35:36.328771Z"
    }
   },
   "outputs": [],
   "source": [
    "df_baseline = pd.DataFrame(baseline)\n",
    "df_baseline = df_baseline.loc[:,['Date','Name','FPTS','PTS','3P','AST','TRB','STL','BLK','TOV','DD','TD']]\n",
    "df_baseline.to_csv(os.path.join(data_dir, 'Dataframes','modelling','baseline','{}.csv'.format(season)),\n",
    "                   index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Statistics and Recency Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:35:36.477081Z",
     "start_time": "2018-05-20T14:35:36.392014Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_weights():\n",
    "    weights_dic = {}\n",
    "    weighting = ['sqrt_0.5','linear_1.0', 'quad_2.0']\n",
    "\n",
    "    for key in weighting:\n",
    "        weights = np.array([np.power(i, float(key[-3:])) for i in range(1,11)])\n",
    "        weights = weights/weights.sum()\n",
    "        weights_dic[key[:-4]] = weights\n",
    "\n",
    "    sns.set_style(\"darkgrid\")\n",
    "\n",
    "    for key in weights_dic.keys():\n",
    "        plt.plot(weights_dic[key])\n",
    "\n",
    "    plt.xlabel('n-th game', fontsize=12)\n",
    "    plt.ylabel('Weight', fontsize=12)\n",
    "    plt.xticks([i for i in range(0,10)], [i for i in range(1,11)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:35:36.957158Z",
     "start_time": "2018-05-20T14:35:36.479549Z"
    }
   },
   "outputs": [],
   "source": [
    "draw_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def calculate_weighted_mean(list weights, values):\n",
    "    n = len(weights)\n",
    "    weighted_sum = [weights[i] * values[i] for i in range(n)]\n",
    "    weighted_mean = sum(weighted_sum) / sum(weights)\n",
    "    \n",
    "    return weighted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:38:54.944890Z",
     "start_time": "2018-05-20T14:35:36.965907Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {'Date':[], 'Name':[], 'FPTS':[], \n",
    "        #New feature\n",
    "        'Rest':[], 'Value':[], 'FPTS_std':[],\n",
    "        #Basic 9 Variables\n",
    "        'PTS':[], '3P':[], 'AST':[], 'TRB':[], 'STL':[], 'BLK':[], 'TOV':[], 'DD':[], 'TD':[],\n",
    "        #Additional Variables from Basketball-Reference.com with SD\n",
    "        'MP':[], 'FT':[], 'FTA':[], 'FGA':[], '3PA':[], 'DRB':[], 'ORB':[],\n",
    "        #Advanced Statistics from Basketball-Reference.com\n",
    "        'USG_perc':[], 'DRtg':[], 'ORtg':[], 'AST_perc':[], 'DRB_perc':[], 'ORB_perc':[],\n",
    "        'BLK_perc':[], 'TOV_perc':[], 'STL_perc':[], 'eFG_perc':[], 'FG_perc':[], '3P_perc':[], 'FT_perc':[]\n",
    "       }\n",
    "\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    date = df.loc[i,'Date']\n",
    "    name = df.loc[i,'Name']    \n",
    "    \n",
    "    df_name = df.loc[df['Name']==name].reset_index(drop=True)\n",
    "    index = df_name.loc[df_name['Date']==date].index[0]\n",
    "    \n",
    "    if index >= 10:\n",
    "        \n",
    "        df_past = df_name[index-10:index].reset_index(drop=True)\n",
    "        \n",
    "        #Consider the number of days between the current game and the previous game\n",
    "        current = datetime.strptime(str(df_name.loc[index, 'Date']), '%Y%m%d')\n",
    "        previous = datetime.strptime(str(df_past.loc[df_past.shape[0]-1, 'Date']), '%Y%m%d')\n",
    "        rest = current - previous\n",
    "        \n",
    "        data['Rest'].append(rest.days)\n",
    "        \n",
    "        \n",
    "        #Weights higehr towards the most recent game\n",
    "        \n",
    "        if weighting == 'linear':\n",
    "            weights = [i for i in range(1,11)]\n",
    "        \n",
    "        elif weighting == 'quad':\n",
    "            weights = [i**2 for i in range(1,11)]\n",
    "        \n",
    "        elif weighting == 'sqrt':\n",
    "            weights = [i**(1/2) for i in range(1,11)]\n",
    "            \n",
    "\n",
    "        for key in data.keys():\n",
    "            \n",
    "            if key in ['Date', 'Name', 'FPTS']:\n",
    "                data[key].append(df_name.loc[index, key])\n",
    "            elif key == 'FPTS_std':\n",
    "                data[key].append(df_past['FPTS'].std())\n",
    "            elif key != 'Rest':\n",
    "                weighted_mean = calculate_weighted_mean(weights, df_past[key])\n",
    "                data[key].append(weighted_mean)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:38:55.048294Z",
     "start_time": "2018-05-20T14:38:54.947205Z"
    }
   },
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Starter, Listed Position and Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:38:55.079010Z",
     "start_time": "2018-05-20T14:38:55.051088Z"
    }
   },
   "outputs": [],
   "source": [
    "df_features = pd.merge(df.loc[:,['Date','Name','Salary', 'Team','Pos', 'Starter', 'Home']], df_features, on=['Date','Name'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Add Broader Positions and Roster Availability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:38:55.138078Z",
     "start_time": "2018-05-20T14:38:55.081339Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_positions(df):\n",
    "    \n",
    "    PG, SG, F, C = [], [], [] ,[]\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        if 'PG' in df.loc[i,'Pos']:\n",
    "            PG.append(1)\n",
    "            SG.append(0)\n",
    "            F.append(0)\n",
    "            C.append(0)\n",
    "            \n",
    "        elif 'SG' in df.loc[i,'Pos']:\n",
    "            PG.append(0)\n",
    "            SG.append(1)\n",
    "            F.append(0)\n",
    "            C.append(0)\n",
    "        \n",
    "        elif 'C' in df.loc[i,'Pos']:\n",
    "            PG.append(0)\n",
    "            SG.append(0)\n",
    "            F.append(0)\n",
    "            C.append(1)\n",
    "            \n",
    "        else:\n",
    "            PG.append(0)\n",
    "            SG.append(0)\n",
    "            F.append(1)\n",
    "            C.append(0)\n",
    "\n",
    "    df['PG'] = PG\n",
    "    df['SG'] = SG\n",
    "    df['F'] = F\n",
    "    df['C'] = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:38:55.237900Z",
     "start_time": "2018-05-20T14:38:55.140232Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_roster_info(df):\n",
    "    df['Rota_All'] = [0 for i in range(df.shape[0])]\n",
    "    df['Rota_Pos'] = [0 for i in range(df.shape[0])]\n",
    "\n",
    "    for date in tqdm(list(set(df['Date']))):\n",
    "        for team in list(set(df['Team'])):\n",
    "            df_rota = df.loc[(df['Date']==date)&(df['Team']==team)]\n",
    "\n",
    "            if df_rota.shape[0] != 0:\n",
    "                rota_all = df_rota.shape[0]\n",
    "\n",
    "                for pos in ['PG','SG', 'F', 'C']:\n",
    "                    df_pos = df_rota.loc[df_rota[pos]==1]\n",
    "                    rota_pos = df_pos.shape[0]\n",
    "\n",
    "                    df.loc[(df['Date']==date) & (df['Team']==team) & (df[pos]==1), 'Rota_All']=rota_all\n",
    "                    df.loc[(df['Date']==date) & (df['Team']==team) & (df[pos]==1), 'Rota_Pos']=rota_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:40:54.588423Z",
     "start_time": "2018-05-20T14:38:55.239999Z"
    }
   },
   "outputs": [],
   "source": [
    "add_positions(df_features)\n",
    "add_roster_info(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:40:54.593511Z",
     "start_time": "2018-05-20T14:40:54.590036Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plot position distribution\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=False)\n",
    "\n",
    "positions = df_features.drop_duplicates(subset=['Name'])\n",
    "\n",
    "labels = ['PG', 'SG', 'F', 'C']\n",
    "values = [positions[labels[i]].sum() for i in range(4)]\n",
    "\n",
    "trace = go.Pie(labels=labels, values=values)\n",
    "\n",
    "layout = go.Layout(\n",
    "        title = 'Distribution of Broader Positions',\n",
    "        legend = {\"x\":0.8, 'y':1, 'borderwidth': 1},\n",
    "        hovermode = 'closest',\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:40:54.722470Z",
     "start_time": "2018-05-20T14:40:54.595255Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['Date', 'Name', 'Team', 'Pos', 'FPTS', 'Salary',\n",
    "           #Additional Features\n",
    "           'Starter', 'Rest', 'Rota_All','Rota_Pos', 'Home',\n",
    "           'PG', 'SG', 'F', 'C', 'Value', 'FPTS_std',\n",
    "           #Basic Stats with weighted mean\n",
    "           'PTS', '3P',  'AST', 'TRB', \n",
    "           'STL', 'BLK', 'TOV', 'DD', 'TD',\n",
    "           #Additional Stats with weighted mean\n",
    "           'MP', 'FT', 'FTA', 'FGA', '3PA', 'DRB', 'ORB', \n",
    "           #Advanced Stats with weighted mean\n",
    "           'USG_perc', 'DRtg', 'ORtg', 'AST_perc', 'DRB_perc', 'ORB_perc',\n",
    "           'BLK_perc', 'TOV_perc', 'STL_perc', 'eFG_perc', 'FG_perc', '3P_perc', 'FT_perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:40:54.807970Z",
     "start_time": "2018-05-20T14:40:54.725070Z"
    }
   },
   "outputs": [],
   "source": [
    "df_features = df_features.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T14:40:56.293672Z",
     "start_time": "2018-05-20T14:40:54.812897Z"
    }
   },
   "outputs": [],
   "source": [
    "df_features.to_csv(os.path.join(data_dir, 'Dataframes','modelling','features', \\\n",
    "                                weighting,'df_features_{}.csv'.format(season)),\n",
    "                   index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
