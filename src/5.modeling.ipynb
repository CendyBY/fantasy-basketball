{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T12:28:32.643440Z",
     "start_time": "2018-05-20T12:28:32.606527Z"
    }
   },
   "source": [
    "### Model Construction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T11:06:45.777237Z",
     "start_time": "2019-05-28T11:06:44.698651Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from constants import DATA_DIR\n",
    "from utils import csv_concatenate, calculate_FPTS, calculate_MAE, calculate_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T11:08:48.908143Z",
     "start_time": "2019-05-28T11:08:48.905408Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T10:58:19.096351Z",
     "start_time": "2019-05-28T10:58:19.092078Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T10:58:19.643409Z",
     "start_time": "2019-05-28T10:58:19.638700Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:51:26.318501Z",
     "start_time": "2019-05-27T13:51:26.309391Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cross_val(reg_base, X, y, nfolds=5, verbose=1):\n",
    "    mae_results_train, rmse_results_train = [], []\n",
    "    mae_results_valid, rmse_results_valid = [], []\n",
    "\n",
    "    for i in tqdm(range(nfolds)):\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X, y, test_size=1/nfolds, stratify=None, random_state=i)\n",
    "\n",
    "        reg = reg_base\n",
    "\n",
    "        reg.fit(X_train, y_train)\n",
    "        y_pred_train = reg.predict(X_train)\n",
    "\n",
    "        mae_results_train.append(calculate_MAE(y_pred_train, y_train))\n",
    "        rmse_results_train.append(calculate_RMSE(y_pred_train, y_train))\n",
    "\n",
    "        y_pred_valid = reg.predict(X_valid)\n",
    "\n",
    "        mae_results_test.append(calculate_MAE(y_pred_valid, y_valid))\n",
    "        rmse_results_test.append(calculate_RMSE(y_pred_valid, y_valid))\n",
    "\n",
    "    if verbose == 1:\n",
    "        print('[Training Eror]')\n",
    "        print(\"RMSE: {} +- {}\".format(round(cv_result['rmse-mean'][min_index],7),\n",
    "                              round(cv_result['rmse-stdv'][min_index],7)))\n",
    "        print('MAE: {0:10.7f} +- {0:10.7f}'.format(np.mean(mae_results_train), np.std(mae_results_train))\n",
    "        print('MAE: {0:10.7f} +- {0:10.7f}'.format(np.mean(mae_results_train), np.std(mae_results_train))\n",
    "        \n",
    "        print('\\n[TEST]')\n",
    "\n",
    "    print('MAE:', np.mean(mae_results_test))\n",
    "    print('RMSE:', np.mean(rmse_results_test))\n",
    "    return rmse_results_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T11:11:41.651909Z",
     "start_time": "2019-05-28T11:11:41.645026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4714045207910317"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([1,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Baseline - Simple Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:51:45.744876Z",
     "start_time": "2019-05-27T13:51:28.108549Z"
    }
   },
   "outputs": [],
   "source": [
    "df_baseline = csv_concatenate(os.path.join(DATA_DIR, 'Dataframes','Modelling', 'Baseline'))\n",
    "df_baseline['FPTS_pred'] = calculate_FPTS(df_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:53:17.012205Z",
     "start_time": "2019-05-27T13:53:14.797807Z"
    }
   },
   "outputs": [],
   "source": [
    "print('MAE:', calculate_MAE(df_baseline['FPTS_pred'], df_baseline['FPTS']))\n",
    "print('RMSE:', calculate_RMSE(df_baseline['FPTS_pred'], df_baseline['FPTS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:16:34.494233Z",
     "start_time": "2018-04-09T13:16:33.368260Z"
    }
   },
   "source": [
    "### Linear Regression with basic 9 variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:53:41.397826Z",
     "start_time": "2019-05-27T13:53:39.999047Z"
    }
   },
   "outputs": [],
   "source": [
    "df_baseline = df_baseline.sort_values(by=['Date','Name']).reset_index(drop=True)\n",
    "basic =  ['PTS','3P','AST','TRB','STL','BLK','TOV', 'DD', 'TD']\n",
    "\n",
    "X = df_baseline.loc[:, basic]\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "y = df_baseline['FPTS'].values.reshape(-1,1).flatten()\n",
    "\n",
    "reg = LinearRegression()\n",
    "cross_val(reg, X, y, show_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:28:27.367757Z",
     "start_time": "2018-04-09T13:28:27.364972Z"
    }
   },
   "source": [
    "### 3. Weighted Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T15:22:03.411890Z",
     "start_time": "2018-04-09T15:22:00.140237Z"
    }
   },
   "source": [
    "Choose weighting scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:53:48.907719Z",
     "start_time": "2019-05-27T13:53:48.902748Z"
    }
   },
   "outputs": [],
   "source": [
    "original_stats = ['SG', 'F', 'C', 'PTS', '3P', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'DD', 'TD', 'MP', 'FT',\n",
    "                  'FTA', 'FGA', '3PA', 'DRB', 'ORB', 'USG_perc', 'DRtg', 'ORtg', 'AST_perc', 'DRB_perc',\n",
    "                  'ORB_perc', 'BLK_perc', 'TOV_perc', 'STL_perc', 'eFG_perc', 'FG_perc', '3P_perc', 'FT_perc']\n",
    "len(original_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the best weighting scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:54:01.886372Z",
     "start_time": "2019-05-27T13:53:50.958834Z"
    }
   },
   "outputs": [],
   "source": [
    "for weighting in ['sqrt', 'linear', 'quad']:\n",
    "    df_features = csv_concatenate(os.path.join(DATA_DIR, 'Dataframes','Modelling', 'Features', weighting))  \n",
    "    \n",
    "    X = df_features.loc[:, original_stats]\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    y = df_features['FPTS'].values.reshape(-1,1).flatten()\n",
    "\n",
    "    reg = LinearRegression()\n",
    "    cross_val(reg, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:54:26.775649Z",
     "start_time": "2019-05-27T13:54:10.217382Z"
    }
   },
   "outputs": [],
   "source": [
    "weighting = 'linear'\n",
    "\n",
    "df_features = csv_concatenate(os.path.join(DATA_DIR, 'Dataframes','Modelling', 'Features', weighting))\n",
    "df_features['FPTS_pred'] = calculate_FPTS(df_features)\n",
    "\n",
    "print('MAE:', calculate_MAE(df_features['FPTS_pred'], df_features['FPTS']))\n",
    "print('RMSE:', calculate_RMSE(df_features['FPTS_pred'], df_features['FPTS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with basic 9 variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:55:18.437367Z",
     "start_time": "2019-05-27T13:55:17.166946Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_features.loc[:, basic]\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "y = df_features['FPTS'].values.reshape(-1,1).flatten()\n",
    "\n",
    "reg = LinearRegression()\n",
    "cross_val(reg, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection with Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:55:21.580303Z",
     "start_time": "2019-05-27T13:55:21.571896Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['Salary', 'Starter', 'Rest', 'Rota_All', 'Rota_Pos', 'Home', 'SG', 'F', 'C', 'Value', 'FPTS_std',\n",
    "             'PTS', '3P', 'AST', 'TRB', 'STL', 'BLK', 'TOV', 'DD', 'TD', 'MP', 'FT', 'FTA', 'FGA', '3PA', 'DRB',\n",
    "             'ORB', 'USG_perc', 'DRtg', 'ORtg', 'AST_perc', 'DRB_perc', 'ORB_perc', 'BLK_perc', 'TOV_perc', \n",
    "             'STL_perc', 'eFG_perc', 'FG_perc', '3P_perc', 'FT_perc']\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:55:25.127304Z",
     "start_time": "2019-05-27T13:55:25.010483Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_features.loc[:, features]\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "y = df_features['FPTS'].values.reshape(-1,1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:56:06.747325Z",
     "start_time": "2019-05-27T13:55:30.613534Z"
    }
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:56:11.401229Z",
     "start_time": "2019-05-27T13:56:10.886894Z"
    }
   },
   "outputs": [],
   "source": [
    "top_features = pd.Series(model.feature_importances_, index = features).sort_values()\n",
    "top_features.plot(kind = \"barh\", figsize=(15,10) ,title='Top Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:56:15.347127Z",
     "start_time": "2019-05-27T13:56:15.342586Z"
    }
   },
   "outputs": [],
   "source": [
    "omit_lowest = 10\n",
    "selected = list(top_features[omit_lowest:].index)\n",
    "len(top_features[omit_lowest:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T13:29:55.985615Z",
     "start_time": "2018-04-09T13:29:55.982597Z"
    }
   },
   "source": [
    "### Linear Regression with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:56:19.500930Z",
     "start_time": "2019-05-27T13:56:17.329905Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_features.loc[:, selected]\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "y = df_features['FPTS'].values.reshape(-1,1).flatten()\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "reg.fit(X, y)\n",
    "cross_val(reg, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM and Hyperparameter Tuning with Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:56:24.298553Z",
     "start_time": "2019-05-27T13:56:24.258030Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.observer import JSONLogger, ScreenLogger\n",
    "from bayes_opt.event import Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T15:20:48.897806Z",
     "start_time": "2019-05-27T15:20:48.808207Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_features.loc[:, features]\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T15:20:49.748916Z",
     "start_time": "2019-05-27T15:20:49.719164Z"
    }
   },
   "outputs": [],
   "source": [
    "def bayes_parameter_opt_lgb(X, y, init_round, opt_round, n_folds, random_seed):\n",
    "    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n",
    "\n",
    "    def lgb_eval(feature_fraction, bagging_fraction, lambda_l1, lambda_l2, max_depth, num_leaves, \n",
    "                 min_split_gain, min_child_weight, learning_rate, n_estimators):\n",
    "        params = {\n",
    "            \"objective\" : \"regression\",\n",
    "            \"max_bin\": 255,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"min_child_samples\": 20,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"verbosity\": 1,\n",
    "            \"early_stopping_round\": 200,\n",
    "            \"metric\" : 'rmse'\n",
    "        }\n",
    "        \n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['lambda_l1'] = max(lambda_l1, 0)\n",
    "        params['lambda_l2'] = max(lambda_l2, 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['num_leaves'] = int(round(num_leaves))\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        params['learning_rate'] = learning_rate\n",
    "        params['n_estimators'] = int(round(n_estimators))\n",
    "        \n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed,\n",
    "                           verbose_eval=None, stratified=False)\n",
    "        \n",
    "        # Print RMSE for each round of lgbBO for rough tracking of the optimization process\n",
    "        min_index = cv_result['rmse-mean'].index(min(cv_result['rmse-mean']))\n",
    "        print(\"RMSE: {} +- {}\".format(round(cv_result['rmse-mean'][min_index],7),\n",
    "                                      round(cv_result['rmse-stdv'][min_index],7)))\n",
    "        \n",
    "        return (-1.0 * np.array(cv_result['rmse-mean'])).max()\n",
    "    \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'feature_fraction': (0.3, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'lambda_l1': (0, 5),\n",
    "                                            'lambda_l2': (0, 3),\n",
    "                                            'max_depth': (5, 200),\n",
    "                                            'num_leaves' : (10, 500),\n",
    "                                            'min_split_gain': (0.001, 0.1),\n",
    "                                            'min_child_weight': (0, 10),\n",
    "                                            'learning_rate': (0.01, 0.1),\n",
    "                                            'n_estimators': (100, 5000)\n",
    "                                           },\n",
    "                                 random_state=random_seed)\n",
    "    \n",
    "    # Save progress for each round into a JSON file which can be monitored on a editor (i.e. VSCode)\n",
    "    # This somehow suppresses the terminal output (https://github.com/fmfn/BayesianOptimization/issues/167)\n",
    "    logger = JSONLogger(path=DATA_DIR+\"/Logs/{}.json\".format(pd.Timestamp.now().strftime('%Y%m%d-%Hh%Mm')))\n",
    "    lgbBO.subscribe(Events.OPTMIZATION_STEP, logger)\n",
    "    \n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round, acq='ei')\n",
    "    \n",
    "    return lgbBO.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:30:54.972000Z",
     "start_time": "2019-05-27T15:20:53.395379Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt_params = bayes_parameter_opt_lgb(X, y,\n",
    "                                     init_round=50,\n",
    "                                     opt_round=50,\n",
    "                                     n_folds=5,\n",
    "                                     random_seed=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:56:34.350615Z",
     "start_time": "2019-05-27T13:56:34.333910Z"
    }
   },
   "outputs": [],
   "source": [
    "df_params = pd.read_json(DATA_DIR+'/Logs/20190527-10h37m.json', lines=True)\n",
    "df_params = df_params.loc[:,['target', 'params']].sort_values(by='target', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:56:42.646443Z",
     "start_time": "2019-05-27T13:56:42.629956Z"
    }
   },
   "outputs": [],
   "source": [
    "df_params.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:56:44.949376Z",
     "start_time": "2019-05-27T13:56:44.946277Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_params = df_params.loc[0, 'params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:56:45.674791Z",
     "start_time": "2019-05-27T13:56:45.669395Z"
    }
   },
   "outputs": [],
   "source": [
    "for key in opt_params.keys():\n",
    "    if key in ['max_depth', 'num_leaves', 'n_estimators']:\n",
    "        opt_params[key] = int(round(opt_params[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:02:37.511636Z",
     "start_time": "2019-05-27T13:57:03.030137Z"
    }
   },
   "outputs": [],
   "source": [
    "err_buf = []\n",
    "n_iters = 5\n",
    "\n",
    "for i in tqdm(range(n_iters)):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "    d_train = lgb.Dataset(X_train, label=y_train)\n",
    "    d_valid = lgb.Dataset(X_valid, label=y_valid)\n",
    "    watchlist = [d_valid]\n",
    "    \n",
    "    model = lgb.train(opt_params, d_train, watchlist, verbose_eval=1)\n",
    "\n",
    "    preds = model.predict(X_valid)\n",
    "    err = calculate_RMSE(preds, y_valid)    \n",
    "    err_buf.append(err)\n",
    "    print('RMSE: ' + str(err))\n",
    "    \n",
    "print('\\nMean RMSE: ' + str(np.mean(err_buf)) + ' +/- ' + str(np.std(err_buf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:06:24.670956Z",
     "start_time": "2019-05-27T14:02:43.039353Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "opt_params_xgb = {'max_depth':6, 'n_estimators':250, 'min_child_weight':4, 'colsample_bytree':0.6, \n",
    "                  'colsample_bylevel':0.7, 'subsample':1.0, 'gamma':0.0, 'learning_rate':0.026944654231987667}\n",
    "\n",
    "reg = xgb.XGBRegressor(**opt_params_xgb)\n",
    "cross_val(reg, X, y, show_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###  Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:08:14.427550Z",
     "start_time": "2019-05-27T14:08:13.459402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:08:15.410607Z",
     "start_time": "2019-05-27T14:08:15.406519Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "es_cb = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:08:17.140565Z",
     "start_time": "2019-05-27T14:08:17.133748Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def model_1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X.shape[1], input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:08:19.475446Z",
     "start_time": "2019-05-27T14:08:19.467359Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X.shape[1], input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:08:20.213845Z",
     "start_time": "2019-05-27T14:08:20.208794Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def model_3():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X.shape[1], input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:10:04.039274Z",
     "start_time": "2019-05-27T14:08:23.171035Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=model_1,\n",
    "                       epochs=30,\n",
    "                       batch_size=32,\n",
    "                       validation_split=0.2,\n",
    "                       shuffle=True,\n",
    "                       verbose=1)\n",
    "h1 = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:10:23.413579Z",
     "start_time": "2019-05-27T14:10:23.194699Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(h1.history['loss'])  \n",
    "plt.plot(h1.history['val_loss'])  \n",
    "plt.title('Model Loss')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['Train', 'Validation'], loc='upper right')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:12:49.002435Z",
     "start_time": "2019-05-27T14:10:32.084294Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=model_2,\n",
    "                       epochs=30,\n",
    "                       batch_size=32,\n",
    "                       validation_split=0.2,\n",
    "                       shuffle=True,\n",
    "                       verbose=1)\n",
    "\n",
    "h2 = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:15:21.897382Z",
     "start_time": "2019-05-27T14:13:22.256098Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=model_3,\n",
    "                       epochs=30,\n",
    "                       batch_size=32,\n",
    "                       validation_split=0.2,\n",
    "                       shuffle=True,\n",
    "                       verbose=1)\n",
    "\n",
    "h3 = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:15:47.529864Z",
     "start_time": "2019-05-27T14:15:47.080199Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for hist in [h1, h3]:\n",
    "    plt.subplot(111)  \n",
    "    plt.plot(hist.history['loss'])  \n",
    "    plt.plot(hist.history['val_loss'])  \n",
    "    plt.title('Model Loss')  \n",
    "    plt.ylabel('Loss')  \n",
    "    plt.xlabel('Epoch')  \n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:15:51.061919Z",
     "start_time": "2019-05-27T14:15:51.057743Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=model_1,\n",
    "                       epochs=30,\n",
    "                       batch_size=32,\n",
    "                       validation_split=0.2,\n",
    "                       shuffle=True,\n",
    "                       verbose=1)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:34:55.346833Z",
     "start_time": "2019-05-27T14:15:54.100815Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_MAE = cross_val_score(model, X, y, cv=kfold, n_jobs=1, scoring='neg_mean_absolute_error')\n",
    "results_RMSE = cross_val_score(model, X, y, cv=kfold, n_jobs=1, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:34:59.524098Z",
     "start_time": "2019-05-27T14:34:59.518574Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(np.sqrt(-results_RMSE))\n",
    "print(\"Results: %.4f RMSE\" % np.sqrt(np.mean(-results_RMSE)))\n",
    "\n",
    "print(np.sqrt(-results_MAE))\n",
    "print(\"Results: %.4f MAE\" % np.mean(-results_MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:40:02.761425Z",
     "start_time": "2019-05-27T14:40:02.753910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=model_3,\n",
    "                       epochs=15,\n",
    "                       batch_size=32,\n",
    "                       validation_split=0.2,\n",
    "                       shuffle=True,\n",
    "                       verbose=2)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:44:42.959763Z",
     "start_time": "2019-05-27T14:42:46.307952Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results_MAE = cross_val_score(model, X, y, cv=kfold, n_jobs=1, scoring='neg_mean_absolute_error')\n",
    "results_RMSE = cross_val_score(model, X, y, cv=kfold, n_jobs=1, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-20T12:27:06.254825Z",
     "start_time": "2018-05-20T12:27:06.245242Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(np.sqrt(-results_RMSE))\n",
    "print(\"Results: %.4f RMSE\" % np.sqrt(np.mean(-results_RMSE)))\n",
    "\n",
    "print(np.sqrt(-results_MAE))\n",
    "print(\"Results: %.4f MAE\" % np.mean(-results_MAE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:55:34.373874Z",
     "start_time": "2019-05-27T14:55:34.238741Z"
    }
   },
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "X = df_features.sort_values(by=['Date','Name']).reset_index(drop=True)\n",
    "\n",
    "target_month = 201903\n",
    "\n",
    "start = 20190301\n",
    "end = 20190331\n",
    "\n",
    "test_indices = (df_features['Date'] >= start) & (df_features['Date'] <= end)\n",
    "train_indices = [not value for value in test_indices]\n",
    "\n",
    "X_train = df_features.loc[train_indices, selected]\n",
    "X_test = df_features.loc[test_indices, selected]\n",
    "\n",
    "y_train = df_features.loc[train_indices, 'FPTS'].values.reshape(-1,1).flatten()\n",
    "y_test = df_features.loc[test_indices, 'FPTS'].values.reshape(-1,1).flatten()\n",
    "\n",
    "# X_train = MinMaxScaler().fit_transform(X_train)\n",
    "# X_test = MinMaxScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:55:35.026765Z",
     "start_time": "2019-05-27T14:55:35.021823Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:55:37.371547Z",
     "start_time": "2019-05-27T14:55:37.243441Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_baseline = df_baseline.loc[(df_baseline['Date'] >= start) & (df_baseline['Date'] <= end), 'FPTS_pred'].reset_index(drop=True)\n",
    "actual = df_baseline.loc[(df_baseline['Date'] >= start) & (df_baseline['Date'] <= end), 'FPTS'].reset_index(drop=True)\n",
    "\n",
    "print(calculate_MAE(pred_baseline, actual))\n",
    "print(calculate_RMSE(pred_baseline, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:55:38.239973Z",
     "start_time": "2019-05-27T14:55:38.054908Z"
    }
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "pred_lm = reg.predict(X_test)\n",
    "\n",
    "print(calculate_MAE(pred_lm, y_test))\n",
    "print(calculate_RMSE(pred_lm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T14:59:04.006555Z",
     "start_time": "2019-05-27T14:57:31.950692Z"
    }
   },
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "d_test = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "watchlist = [d_valid]\n",
    "\n",
    "opt_params = df_params.loc[0, 'params']\n",
    "\n",
    "model = lgb.train(opt_params, d_train, watchlist, verbose_eval=1)\n",
    "pred_gbm = model.predict(X_test)\n",
    "\n",
    "print(calculate_MAE(pred_gbm, y_test))\n",
    "print(calculate_RMSE(pred_gbm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T15:02:00.158790Z",
     "start_time": "2019-05-27T15:01:19.663640Z"
    }
   },
   "outputs": [],
   "source": [
    "best_parameters = {'max_depth':6, 'n_estimators':250, 'min_child_weight':4, 'colsample_bytree':0.6, \n",
    "                   'colsample_bylevel':0.7, 'subsample':1.0, 'gamma':0.0, 'learning_rate':0.026944654231987667}\n",
    "\n",
    "reg = xgb.XGBRegressor(**best_parameters)\n",
    "reg.fit(X_train, y_train, verbose=1)\n",
    "pred_xgb = reg.predict(X_test)\n",
    "\n",
    "print(calculate_MAE(pred_xgb, y_test))\n",
    "print(calculate_RMSE(pred_xgb, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T15:04:47.955013Z",
     "start_time": "2019-05-27T15:04:47.947277Z"
    }
   },
   "outputs": [],
   "source": [
    "def advanced_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T15:07:30.926434Z",
     "start_time": "2019-05-27T15:04:54.585879Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=advanced_model,\n",
    "                       epochs=30,\n",
    "                       batch_size=64,\n",
    "                       validation_split=0.2,\n",
    "                       shuffle=True,\n",
    "                       verbose=1)\n",
    "\n",
    "h = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T15:08:10.612725Z",
     "start_time": "2019-05-27T15:08:10.150268Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_nn = model.predict(X_test)\n",
    "print(calculate_MAE(pred_nn, y_test))\n",
    "print(calculate_RMSE(pred_nn, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write prediction into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T23:07:32.106449Z",
     "start_time": "2019-05-27T23:07:32.095584Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred = df_features.loc[test_indices, ['Date', 'Name', 'Team', 'FPTS', 'Pos', 'Salary']]\n",
    "df_pred['Pred'] = pred_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T23:07:34.511977Z",
     "start_time": "2019-05-27T23:07:34.463353Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred.to_csv(os.path.join(DATA_DIR, 'Predictions/{}.csv'.format(pd.Timestamp.now().strftime('%Y%m%d-%Hh%Mm'))), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
